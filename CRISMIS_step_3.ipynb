{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRISMIS3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJb7Y9YrJ8XJ"
      },
      "source": [
        "#importing important libraries\n",
        "import requests\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS_jLxbQKE9l"
      },
      "source": [
        "# checks the validity of the url\n",
        "# url should have netloc(domain name) and scheme(protocol)\n",
        "def is_valid(url):\n",
        "    parsed = urlparse(url)\n",
        "    return bool(parsed.netloc) and bool(parsed.scheme)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnpU3hhaZe4k"
      },
      "source": [
        "# makes the url of a particular year and day\n",
        "def get_url_from_day_year (year,day):\n",
        "  url = \"https://pdsimage2.wr.usgs.gov/archive/mess-e_v_h-mdis-2-edr-rawdata-v1.0/MSGRMDS_1001/DATA/\" + str(year) + '_' + str(day) + '/'\n",
        "  return url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQJoqbx1TuNA"
      },
      "source": [
        "# return a list of all the IMG files which are their on a url of particular year and day.\n",
        "# here input is a particular url which is of that particular year and day.\n",
        "def get_all_images(url):\n",
        "# html parser is used \n",
        "    soup = bs(requests.get(url).content, \"html.parser\")\n",
        "    urls = []\n",
        "    \n",
        "# tqdm is used to see the progress of the loop\n",
        "    for img in tqdm(soup.find_all(\"a\"), \"Extracting images\"):\n",
        "        img_url = img.attrs.get(\"href\")\n",
        "        IMG_checker = \"IMG\"\n",
        "\n",
        "# IMG_checker is used to filter href link that contain .IMG format data. \n",
        "# make the URL absolute by joining domain with the URL that is just extracted\n",
        "# the url is checked for it's validity\n",
        "        if IMG_checker in img_url:\n",
        "          img_url = urljoin(url, img_url)\n",
        "          if is_valid(img_url):\n",
        "            urls.append(img_url)           \n",
        "    return urls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLtJgsDIUVyL"
      },
      "source": [
        "# return a list of urls of all .IMG format image data files of a particular year and day.\n",
        "# here input is year,day\n",
        "\n",
        "def images_list (year,day):\n",
        "  url = get_url_from_day_year (year,day)\n",
        "  images_url_list = get_all_images(url)\n",
        "  return images_url_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBwMVMG26WDR"
      },
      "source": [
        "# shape_function returns a type of shape which is needed for reshaping the array, this has been done for only 4 cases,\n",
        "def shape_function (data):\n",
        "  if len(data) == 134656 : \n",
        "    return (526,256)\n",
        "  if len(data) == 527872 :\n",
        "    return (1031,512)\n",
        "  if len(data) == 1052672:\n",
        "    return (1028,1024)\n",
        "  if len(data) == 528384 :\n",
        "    return (688,768)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5hWP70l4pb9"
      },
      "source": [
        "\n",
        "### **The data from the previous notebook will be used to make models and predict their efficiency**\n",
        "### **the dataset consists of only 4 days data of year 2011, from 4th June to 7th June.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDhA-OK05xyM"
      },
      "source": [
        "The classification .csv file csn be founded here : https://github.com/VIDIT-OSTWAL/CRISMIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXoD7fROhqJX"
      },
      "source": [
        "csv = pd.read_csv(\"/content/url.csv\",header = None,index_col=  False,names = ['File Name','Classification'])\n",
        "csv1 = pd.read_csv(\"/content/url1.csv\",header = None,index_col=  False,names = ['File Name','Classification'])\n",
        "csv2= pd.read_csv(\"/content/url2.csv\",header = None,index_col=  False,names = ['File Name','Classification'])\n",
        "csv3 =  pd.read_csv(\"/content/url3.csv\",header = None,index_col=  False,names = ['File Name','Classification'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyFZp0x1vlJq",
        "outputId": "b3fb0497-32f7-40c8-a546-bb3122e4f180"
      },
      "source": [
        "# again list of all the urls of a particular year and day is created for all the days\n",
        "\n",
        "images_2011_155 = images_list(2011,155)\n",
        "images_2011_156 = images_list(2011,156)\n",
        "images_2011_157 = images_list(2011,157)\n",
        "images_2011_158 = images_list(2011,158)\n",
        "dtype = np.dtype('>u2') # big-endian unsigned integer (16bit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting images: 100%|██████████| 163/163 [00:00<00:00, 32398.42it/s]\n",
            "Extracting images: 100%|██████████| 80/80 [00:00<00:00, 26942.69it/s]\n",
            "Extracting images: 100%|██████████| 123/123 [00:00<00:00, 33644.15it/s]\n",
            "Extracting images: 100%|██████████| 184/184 [00:00<00:00, 23686.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPVGs_3YsL6n"
      },
      "source": [
        "# this function opens a .IMG format file, first reshape it with the shape_function and then resizes it in a (128,128) array, \n",
        "# and then appends that array to a list\n",
        "# it also finds the corresponding classificaiton made agaisnt that particular file and appends that file to another list\n",
        "# interpolation used for resizing is cv2.INTER_CUBIC\n",
        "\n",
        "def making_list_of_data (path_name,list_of_images,list_of_data,list_of_classification,csv):\n",
        "  for url in list_of_images:\n",
        "    file_name  = path_name + url.split(\"/\")[-1]\n",
        "    fid = open(file_name,'rb')\n",
        "    data = np.fromfile(fid,dtype)\n",
        "    shape = shape_function(data) # matrix size\n",
        "    image = data.reshape(shape)\n",
        "    res = cv2.resize(image, dsize=(128,128), interpolation=cv2.INTER_CUBIC)\n",
        "    list_of_data.append(res)\n",
        "    value =  int(csv[csv['File Name'] == url.split(\"/\")[-1]]['Classification'])\n",
        "    list_of_classification.append(value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCfVYdeltNaH"
      },
      "source": [
        "list_of_resized_data = []\n",
        "list_of_classification = []\n",
        "\n",
        "making_list_of_data(\"/content/images/content/images/\",images_2011_157,list_of_resized_data,list_of_classification,csv)\n",
        "making_list_of_data(\"/content/images1/content/images1/\",images_2011_156,list_of_resized_data,list_of_classification,csv1)\n",
        "making_list_of_data(\"/content/images2/content/images2/\",images_2011_155,list_of_resized_data,list_of_classification,csv2)\n",
        "making_list_of_data(\"/content/images3/\",images_2011_158,list_of_resized_data,list_of_classification,csv3)\n",
        "\n",
        "#all the arrays of image file is appended to list_of_resized_data and classification are appended to list_of_classification\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaYjWc40jBZ8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D,Flatten,InputLayer, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z89wpYJ7i6sm"
      },
      "source": [
        "# the previous list are made into nd.arrays\n",
        "new_array = np.array(list_of_resized_data)\n",
        "new_classification = np.array(list_of_classification)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYIcp2DUjVK8"
      },
      "source": [
        "# new_array is reshaped into (530,128*128) flassten to 1D\n",
        "# train and test dataset have been formed with test_size of 0.3\n",
        "\n",
        "new_array = new_array.reshape(530,16384)\n",
        "new_classification = new_classification.astype('float32')\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(new_array,new_classification,test_size = 0.3,random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhPYDigVBB0U"
      },
      "source": [
        "# *A SIMPLE NEURAL NETWORK*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cLp6kgwlYTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af67172-133e-4194-ae66-75ca8bf2188c"
      },
      "source": [
        "# bluiding a simple neural network for prediction\n",
        "\n",
        "model = Sequential()\n",
        "# hidden layer\n",
        "model.add(Dense(100, input_shape=(16384,), activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model for 30 epochs\n",
        "model.fit( X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_61 (Dense)             (None, 100)               1638500   \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 1,639,510\n",
            "Trainable params: 1,639,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "12/12 [==============================] - 1s 31ms/step - loss: 319721.5743 - accuracy: 0.5588 - val_loss: 18762.6211 - val_accuracy: 0.7044\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 56374.1151 - accuracy: 0.7017 - val_loss: 92529.4219 - val_accuracy: 0.7044\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 88720.9228 - accuracy: 0.6910 - val_loss: 56996.6367 - val_accuracy: 0.6981\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 41638.1217 - accuracy: 0.7013 - val_loss: 9919.4072 - val_accuracy: 0.8365\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 20466.3128 - accuracy: 0.7163 - val_loss: 103135.3828 - val_accuracy: 0.7044\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 88609.9459 - accuracy: 0.7132 - val_loss: 113215.7969 - val_accuracy: 0.7044\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 94839.4916 - accuracy: 0.7488 - val_loss: 22496.8809 - val_accuracy: 0.8302\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 31627.6783 - accuracy: 0.7188 - val_loss: 29019.5273 - val_accuracy: 0.8239\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 74255.9352 - accuracy: 0.7780 - val_loss: 52845.6523 - val_accuracy: 0.7987\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 85294.4183 - accuracy: 0.7726 - val_loss: 33589.3945 - val_accuracy: 0.8239\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 47976.3621 - accuracy: 0.7826 - val_loss: 35828.6523 - val_accuracy: 0.8239\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 29196.9127 - accuracy: 0.7624 - val_loss: 19193.8047 - val_accuracy: 0.5849\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 46353.3087 - accuracy: 0.6723 - val_loss: 21121.4434 - val_accuracy: 0.8365\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 48251.0679 - accuracy: 0.7875 - val_loss: 59854.1562 - val_accuracy: 0.7925\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 63189.6166 - accuracy: 0.7762 - val_loss: 21008.9023 - val_accuracy: 0.8365\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 16616.8778 - accuracy: 0.7967 - val_loss: 8470.6494 - val_accuracy: 0.7484\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 12693.8321 - accuracy: 0.7846 - val_loss: 8303.7979 - val_accuracy: 0.7296\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 9398.0075 - accuracy: 0.7992 - val_loss: 17595.1211 - val_accuracy: 0.8302\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 26184.0801 - accuracy: 0.6854 - val_loss: 25312.4219 - val_accuracy: 0.7987\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 22113.1506 - accuracy: 0.7744 - val_loss: 4724.1929 - val_accuracy: 0.8553\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7428.8230 - accuracy: 0.8077 - val_loss: 2982.0874 - val_accuracy: 0.8553\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 4889.9546 - accuracy: 0.8145 - val_loss: 7956.2710 - val_accuracy: 0.8302\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 11327.8839 - accuracy: 0.7884 - val_loss: 1660.6082 - val_accuracy: 0.8742\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4167.2659 - accuracy: 0.8242 - val_loss: 23106.1660 - val_accuracy: 0.3711\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 18539.2991 - accuracy: 0.6488 - val_loss: 16473.9395 - val_accuracy: 0.5472\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 11079.0445 - accuracy: 0.7563 - val_loss: 1729.1993 - val_accuracy: 0.8742\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7573.4037 - accuracy: 0.7861 - val_loss: 39464.5703 - val_accuracy: 0.3459\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 34403.6055 - accuracy: 0.6174 - val_loss: 11991.0186 - val_accuracy: 0.8239\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 10688.5934 - accuracy: 0.8077 - val_loss: 14820.4043 - val_accuracy: 0.8302\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 16104.2798 - accuracy: 0.7505 - val_loss: 11188.7129 - val_accuracy: 0.8365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe4e615510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y86IiGcn9q4i"
      },
      "source": [
        "# The NN model : the accuracy of this model (at the time of running)\n",
        "\n",
        "# acc = 0.7505\n",
        "\n",
        "# val_acc = 0.8365\n",
        "# But the loss function has not converged (the code was run multiple times) , therefore this model accuracy and predictions can not be trusted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLjKDUW74v85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIyqIeSuAr5r"
      },
      "source": [
        "## **A SIMPLE CONVOLUTIONAL NEURAL  NETWORK **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSRFNkT1uJ_9"
      },
      "source": [
        "new_array = np.array(list_of_resized_data)\n",
        "new_classification = np.array(list_of_classification)\n",
        "\n",
        "# the new_array is reshaped to (number_of_example,128,128,1)\n",
        "\n",
        "new_array = new_array.reshape(new_array.shape[0],128,128,1)\n",
        "new_classification = new_classification.astype('float32')\n",
        "X_train,X_test,y_train,y_test = train_test_split(new_array,new_classification,test_size = 0.3,random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvBpEWTJlr-y"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(128,128,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC3rtByEth_C",
        "outputId": "b7189d2d-7a1c-422c-8e92-8f1aacee8088"
      },
      "source": [
        "# compiling the sequential model\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 8s 628ms/step - loss: 304089.7953 - accuracy: 0.4715 - val_loss: 360315.7812 - val_accuracy: 0.7044\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 7s 584ms/step - loss: 405227.7668 - accuracy: 0.7258 - val_loss: 103353.3203 - val_accuracy: 0.6981\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 79735.0922 - accuracy: 0.7790 - val_loss: 11557.3057 - val_accuracy: 0.8553\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 16659.5229 - accuracy: 0.8010 - val_loss: 75705.2109 - val_accuracy: 0.7799\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 7s 585ms/step - loss: 62870.4522 - accuracy: 0.7618 - val_loss: 57263.0117 - val_accuracy: 0.4151\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 28932.1379 - accuracy: 0.7228 - val_loss: 28833.0684 - val_accuracy: 0.8491\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 7s 581ms/step - loss: 19213.7649 - accuracy: 0.8058 - val_loss: 4817.0493 - val_accuracy: 0.8113\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 4656.5600 - accuracy: 0.8929 - val_loss: 4187.2368 - val_accuracy: 0.8931\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 2228.0867 - accuracy: 0.9537 - val_loss: 4897.3237 - val_accuracy: 0.8176\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 3451.2408 - accuracy: 0.8855 - val_loss: 2988.6052 - val_accuracy: 0.8931\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 516.0246 - accuracy: 0.9533 - val_loss: 2431.1104 - val_accuracy: 0.9119\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 714.2939 - accuracy: 0.9767 - val_loss: 2221.4897 - val_accuracy: 0.9182\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 7s 582ms/step - loss: 1290.0109 - accuracy: 0.9651 - val_loss: 11267.7832 - val_accuracy: 0.8742\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 2956.0638 - accuracy: 0.9330 - val_loss: 4574.7993 - val_accuracy: 0.8931\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 1147.8601 - accuracy: 0.9676 - val_loss: 6364.6978 - val_accuracy: 0.7736\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 7s 582ms/step - loss: 1696.9147 - accuracy: 0.9241 - val_loss: 3760.5549 - val_accuracy: 0.8994\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 267.3734 - accuracy: 0.9634 - val_loss: 1996.5441 - val_accuracy: 0.8931\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 7s 578ms/step - loss: 392.1459 - accuracy: 0.9624 - val_loss: 6234.7744 - val_accuracy: 0.8805\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 7s 576ms/step - loss: 596.1195 - accuracy: 0.9786 - val_loss: 3588.0095 - val_accuracy: 0.9119\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 7s 581ms/step - loss: 1572.7824 - accuracy: 0.9502 - val_loss: 1836.9027 - val_accuracy: 0.9308\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 7s 585ms/step - loss: 958.9816 - accuracy: 0.9768 - val_loss: 2297.5835 - val_accuracy: 0.8742\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 7s 593ms/step - loss: 553.9052 - accuracy: 0.9489 - val_loss: 13112.8652 - val_accuracy: 0.8742\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 7s 577ms/step - loss: 270.0506 - accuracy: 0.9699 - val_loss: 2679.4834 - val_accuracy: 0.8553\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 140.2526 - accuracy: 0.9915 - val_loss: 2253.9460 - val_accuracy: 0.9371\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 191.7355 - accuracy: 0.9839 - val_loss: 4579.5039 - val_accuracy: 0.9182\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 150.3693 - accuracy: 0.9824 - val_loss: 1990.9948 - val_accuracy: 0.8679\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 7s 584ms/step - loss: 78.8226 - accuracy: 0.9920 - val_loss: 1889.5332 - val_accuracy: 0.9434\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 29.6807 - accuracy: 0.9964 - val_loss: 1474.0383 - val_accuracy: 0.9308\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 28.0053 - accuracy: 0.9959 - val_loss: 2470.5581 - val_accuracy: 0.9434\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 7s 589ms/step - loss: 12.9691 - accuracy: 0.9986 - val_loss: 2764.6252 - val_accuracy: 0.8365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe4812f810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EKfaV7Y_vWk"
      },
      "source": [
        "# A simple CNN network the loss has convered to a great extent the accuracy in train_datset is 0.9986 and in the test_dataset is around 0.8365\n",
        "the lost function in case of test_dataset has not convered to a great extent thus some improvment is required \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvW8i7pAovK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7jt0EqcBlcW"
      },
      "source": [
        "# *A DEEP CONVOLUTIONAL NEURAL NETWORK*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i-vdW_x3Wt0",
        "outputId": "fbdbea81-73fc-492e-95c4-f482e86c131d"
      },
      "source": [
        "# build a sequential model\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(128, 128, 1)))\n",
        "\n",
        "# 1st conv block\n",
        "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "# 2nd conv block\n",
        "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "# 3rd conv block\n",
        "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "# ANN block\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "# output layer\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "# fit on data for 30 epochs\n",
        "model.fit(X_train,y_train, epochs=30, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 7s 546ms/step - loss: 1.4441 - accuracy: 0.5112 - val_loss: 1.5024 - val_accuracy: 0.6981\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.4007 - accuracy: 0.8434 - val_loss: 1.4497 - val_accuracy: 0.7044\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 6s 530ms/step - loss: 0.2570 - accuracy: 0.8949 - val_loss: 1.4747 - val_accuracy: 0.8239\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.2469 - accuracy: 0.9102 - val_loss: 0.9424 - val_accuracy: 0.8365\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.1762 - accuracy: 0.9507 - val_loss: 2.0266 - val_accuracy: 0.8428\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 6s 531ms/step - loss: 0.1566 - accuracy: 0.9422 - val_loss: 1.5755 - val_accuracy: 0.8365\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1234 - accuracy: 0.9526 - val_loss: 0.4410 - val_accuracy: 0.8050\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.2027 - accuracy: 0.9377 - val_loss: 2.0727 - val_accuracy: 0.8428\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1403 - accuracy: 0.9496 - val_loss: 1.8377 - val_accuracy: 0.8428\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.1325 - accuracy: 0.9458 - val_loss: 0.8617 - val_accuracy: 0.8428\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.1618 - accuracy: 0.9450 - val_loss: 0.9054 - val_accuracy: 0.8365\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.2930 - accuracy: 0.8908 - val_loss: 0.5522 - val_accuracy: 0.8428\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 6s 531ms/step - loss: 0.1849 - accuracy: 0.9369 - val_loss: 0.5257 - val_accuracy: 0.8491\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1743 - accuracy: 0.9321 - val_loss: 0.5537 - val_accuracy: 0.8428\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.1749 - accuracy: 0.9331 - val_loss: 0.8606 - val_accuracy: 0.8365\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.1256 - accuracy: 0.9607 - val_loss: 0.7424 - val_accuracy: 0.8428\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1239 - accuracy: 0.9536 - val_loss: 0.1664 - val_accuracy: 0.9434\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1514 - accuracy: 0.9354 - val_loss: 0.2584 - val_accuracy: 0.9057\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.2003 - accuracy: 0.9253 - val_loss: 0.1856 - val_accuracy: 0.9245\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.1258 - accuracy: 0.9508 - val_loss: 0.3771 - val_accuracy: 0.8931\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.1251 - accuracy: 0.9619 - val_loss: 0.6085 - val_accuracy: 0.8679\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.0862 - accuracy: 0.9767 - val_loss: 1.9499 - val_accuracy: 0.5975\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 6s 529ms/step - loss: 0.3647 - accuracy: 0.8763 - val_loss: 0.2340 - val_accuracy: 0.9371\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.1137 - accuracy: 0.9620 - val_loss: 0.5330 - val_accuracy: 0.8679\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 6s 530ms/step - loss: 0.1226 - accuracy: 0.9495 - val_loss: 0.3146 - val_accuracy: 0.8868\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 6s 530ms/step - loss: 0.0937 - accuracy: 0.9759 - val_loss: 0.3871 - val_accuracy: 0.8805\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.3758 - val_accuracy: 0.9057\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.1309 - accuracy: 0.9604 - val_loss: 0.3808 - val_accuracy: 0.8994\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.0623 - accuracy: 0.9757 - val_loss: 0.1342 - val_accuracy: 0.9748\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.0708 - accuracy: 0.9641 - val_loss: 0.1581 - val_accuracy: 0.9623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe45f344d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjf47j8A5x3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogneuWlnCnRk"
      },
      "source": [
        "# A deep CNN network has performed very well, the loss function of both train and validation have converged to a great extent and also the accuracy\n",
        "# train_acc = 0.9641\n",
        "# val_acc =  0.9623\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ljymlZDWFO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}